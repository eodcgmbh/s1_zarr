{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "028c77b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from hera.workflows import models, CronWorkflow, script, Artifact, Parameter, DAG, Steps, Step, NoneArchiveStrategy, Workflow\n",
    "from hera.shared import global_config\n",
    "\n",
    "load_dotenv(\"/home/otto/s1_zarr/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "25601f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "global_config.host = \"https://dev.services.eodc.eu/workflows/\"\n",
    "global_config.namespace = \"inca\"\n",
    "global_config.token = os.getenv(\"argo_token\")\n",
    "global_config.image = \"ghcr.io/oscipal/image_zarr:latest\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ed864265",
   "metadata": {},
   "outputs": [],
   "source": [
    "nfs_volume = [models.Volume(\n",
    "    name=\"eodc-mount\",\n",
    "    persistent_volume_claim={\"claimName\": \"eodc-nfs-claim\"},\n",
    "    )]\n",
    "\n",
    "security_context = {\"runAsUser\": 74268,\n",
    "                    \"runAsGroup\": 71473}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bdb9df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@script(volume_mounts=[models.VolumeMount(name=\"eodc-mount\", mount_path=\"/eodc\")])\n",
    "\n",
    "def write_data(tile: str, store_path: str = \"/eodc/private/openeo_platform/zarr_nacho/s1sig0.zarr\"):\n",
    "    import pystac_client as pc\n",
    "    import xarray as xr\n",
    "    import zarr\n",
    "    import numpy as np\n",
    "    import rioxarray\n",
    "    import pandas as pd\n",
    "\n",
    "    def get_idx(array1, array2):\n",
    "        min = np.where(array1==array2[0])[0][0]\n",
    "        max = np.where(array1==array2[-1])[0][0]+1\n",
    "        return min, max\n",
    "\n",
    "    def load_data(item, pols):\n",
    "        if type(pols)==str:\n",
    "            data = rioxarray.open_rasterio(item.assets[pols].href).load().expand_dims(time=pd.to_datetime([item.properties[\"datetime\"]]).tz_convert(None)).rename(pols)\n",
    "        else:\n",
    "            data = []\n",
    "            for pol in pols:\n",
    "                data.append(rioxarray.open_rasterio(item.assets[pol].href).load().expand_dims(time=pd.to_datetime([item.properties[\"datetime\"]]).tz_convert(None)).rename(pol))\n",
    "            \n",
    "            data = xr.merge(data)\n",
    "        return data.squeeze()\n",
    "    \n",
    "    def clip_data(dataset, fillvalue=-9999, multiple_vars = False):\n",
    "        if len(list(dataset.data_vars)) > 1 and not multiple_vars:\n",
    "            raise Warning(\"All variables are clipped to the extent of first variable! Set multiple_vars to TRUE if you want to proceed.\")\n",
    "        mask = dataset[list(dataset.data_vars)[0]]!=fillvalue\n",
    "        ymin, ymax = [np.where(mask)[0].min(), np.where(mask)[0].max()+1]\n",
    "        xmin, xmax = [np.where(mask)[1].min(), np.where(mask)[1].max()+1]\n",
    "        data = dataset.isel(x=slice(xmin, xmax), y=slice(ymin,ymax))\n",
    "        return data\n",
    "\n",
    "    pc_client = pc.Client.open(\"https://stac.eodc.eu/api/v1\")\n",
    "    time_range = \"2022-01-01/2022-01-30\"\n",
    "    print(tile)\n",
    "    search = pc_client.search(\n",
    "        collections=[\"SENTINEL1_SIG0_20M\"],\n",
    "        datetime=time_range,\n",
    "        query={\"Equi7_TileID\": {\"eq\": f\"EU020M_{tile}T3\"}})\n",
    "\n",
    "    items_eodc = search.item_collection()\n",
    "    item_list = list(items_eodc)[::-1]\n",
    "\n",
    "    store = zarr.storage.LocalStore(store_path)\n",
    "    group = zarr.group(store=store)\n",
    "    x_extent = group[\"x\"][:]\n",
    "    y_extent = group[\"y\"][:]\n",
    "\n",
    "    print(len(items_eodc))\n",
    "\n",
    "    for item in item_list:\n",
    "\n",
    "        print(\"alala\")\n",
    "\n",
    "        dataset = load_data(item, [\"VH\", \"VV\"])\n",
    "\n",
    "        dataset[\"x\"] = dataset.x-10\n",
    "        dataset[\"y\"] = dataset.y+10\n",
    "\n",
    "        dataset_clipped = clip_data(dataset, multiple_vars=True)\n",
    "        aon = dataset_clipped.attrs[\"abs_orbit_number\"]\n",
    "        ron = dataset_clipped.attrs[\"rel_orbit_number\"]\n",
    "        dataset = None\n",
    "\n",
    "        time_origin = np.datetime64(\"2014-10-01\")\n",
    "        times = dataset_clipped.time.values.astype(\"datetime64[D]\")\n",
    "        time_delta = (times - time_origin).astype(\"int64\")\n",
    "\n",
    "        sensing_origin = np.datetime64(\"2014-10-01T00:00:00\")\n",
    "        sensing = dataset_clipped.time.values.astype(\"datetime64[s]\")\n",
    "        sensing_delta = (sensing - sensing_origin).astype(\"int64\")\n",
    "\n",
    "        x_min, x_max = get_idx(x_extent, dataset_clipped[\"x\"].values)\n",
    "        y_min, y_max = get_idx(y_extent, dataset_clipped[\"y\"].values)\n",
    "\n",
    "        data_vh = dataset_clipped[\"VH\"].values\n",
    "        existing_data_vh = group[\"VH\"][time_delta, y_min:y_max, x_min:x_max]\n",
    "        np.copyto(existing_data_vh, data_vh, where=(existing_data_vh==-9999))\n",
    "        group[\"VH\"][time_delta, y_min:y_max, x_min:x_max] = existing_data_vh\n",
    "        data_vh = None\n",
    "\n",
    "        data_vv = dataset_clipped[\"VV\"].values\n",
    "        existing_data_vv = group[\"VV\"][time_delta, y_min:y_max, x_min:x_max]\n",
    "        np.copyto(existing_data_vv, data_vv, where=(existing_data_vv==-9999))\n",
    "        group[\"VV\"][time_delta, y_min:y_max, x_min:x_max] = existing_data_vv\n",
    "        data_vv = None\n",
    "        existing_data_vv = None\n",
    "\n",
    "        new_aon = existing_data_vh.astype(np.int32)\n",
    "        new_aon[new_aon!=-9999] = aon\n",
    "        group[\"absolute_orbit_number\"][time_delta, y_min:y_max, x_min:x_max] = new_aon\n",
    "        new_aon = None\n",
    "\n",
    "        new_ron = existing_data_vh\n",
    "        new_ron[new_ron!=-9999] = ron\n",
    "        group[\"relative_orbit_number\"][time_delta, y_min:y_max, x_min:x_max] = new_ron\n",
    "        new_ron = None\n",
    "\n",
    "        new_sensing = existing_data_vh.astype(np.int64)\n",
    "        existing_data_vh = None\n",
    "        new_sensing[new_sensing!=-9999] = int(sensing_delta)\n",
    "        group[\"sensing_date\"][time_delta, y_min:y_max, x_min:x_max] = new_sensing\n",
    "        new_sensing = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "24e92867",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles=[\"E045N015\"]#, \"E048N015\", \"E051N015\"]\n",
    "tiles2 = [\"E048N012\", \"E051N012\"]\n",
    "\n",
    "with Workflow(\n",
    "    generate_name=\"s1sig0-zarr-\",\n",
    "    volumes = nfs_volume,\n",
    "    security_context=security_context,\n",
    "    entrypoint=\"workflow\"\n",
    ") as w:\n",
    "    with DAG(name=\"workflow\"):\n",
    "        a = write_data(name=\"step1\", with_param=tiles)\n",
    "        b = write_data(name=\"step2\", with_param=tiles2)\n",
    "\n",
    "        a>>b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dd05c70d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Workflow(api_version=None, kind=None, metadata=ObjectMeta(annotations=None, cluster_name=None, creation_timestamp=Time(__root__=datetime.datetime(2025, 7, 21, 7, 8, 50, tzinfo=datetime.timezone.utc)), deletion_grace_period_seconds=None, deletion_timestamp=None, finalizers=None, generate_name='s1sig0-zarr-', generation=1, labels={'workflows.argoproj.io/creator': 'system-serviceaccount-default-jenkins'}, managed_fields=[ManagedFieldsEntry(api_version='argoproj.io/v1alpha1', fields_type='FieldsV1', fields_v1=FieldsV1(), manager='argo', operation='Update', subresource=None, time=Time(__root__=datetime.datetime(2025, 7, 21, 7, 8, 50, tzinfo=datetime.timezone.utc)))], name='s1sig0-zarr-8852z', namespace='inca', owner_references=None, resource_version='313471075', self_link=None, uid='fabe8cab-4242-4209-ab5d-3363e1523b42'), spec=WorkflowSpec(active_deadline_seconds=None, affinity=None, archive_logs=None, arguments=Arguments(artifacts=None, parameters=None), artifact_gc=None, artifact_repository_ref=None, automount_service_account_token=None, dns_config=None, dns_policy=None, entrypoint='workflow', executor=None, hooks=None, host_aliases=None, host_network=None, image_pull_secrets=None, metrics=None, node_selector=None, on_exit=None, parallelism=None, pod_disruption_budget=None, pod_gc=None, pod_metadata=None, pod_priority=None, pod_priority_class_name=None, pod_spec_patch=None, priority=None, retry_strategy=None, scheduler_name=None, security_context=PodSecurityContext(fs_group=None, fs_group_change_policy=None, run_as_group=71473, run_as_non_root=None, run_as_user=74268, se_linux_options=None, seccomp_profile=None, supplemental_groups=None, sysctls=None, windows_options=None), service_account_name=None, shutdown=None, suspend=None, synchronization=None, template_defaults=None, templates=[Template(active_deadline_seconds=None, affinity=None, archive_location=None, automount_service_account_token=None, container=None, container_set=None, daemon=None, dag=DAGTemplate(fail_fast=None, target=None, tasks=[DAGTask(arguments=Arguments(artifacts=None, parameters=[Parameter(default=None, description=None, enum=None, global_name=None, name='tile', value='{{item}}', value_from=None)]), continue_on=None, dependencies=None, depends=None, hooks=None, inline=None, name='step1', on_exit=None, template='write-data', template_ref=None, when=None, with_items=None, with_param='[\"E045N015\"]', with_sequence=None), DAGTask(arguments=Arguments(artifacts=None, parameters=[Parameter(default=None, description=None, enum=None, global_name=None, name='tile', value='{{item}}', value_from=None)]), continue_on=None, dependencies=None, depends='step1', hooks=None, inline=None, name='step2', on_exit=None, template='write-data', template_ref=None, when=None, with_items=None, with_param='[\"E048N012\", \"E051N012\"]', with_sequence=None)]), data=None, executor=None, fail_fast=None, host_aliases=None, http=None, init_containers=None, inputs=Inputs(artifacts=None, parameters=None), memoize=None, metadata=Metadata(annotations=None, labels=None), metrics=None, name='workflow', node_selector=None, outputs=Outputs(artifacts=None, exit_code=None, parameters=None, result=None), parallelism=None, plugin=None, pod_spec_patch=None, priority=None, priority_class_name=None, resource=None, retry_strategy=None, scheduler_name=None, script=None, security_context=None, service_account_name=None, sidecars=None, steps=None, suspend=None, synchronization=None, timeout=None, tolerations=None, volumes=None), Template(active_deadline_seconds=None, affinity=None, archive_location=None, automount_service_account_token=None, container=None, container_set=None, daemon=None, dag=None, data=None, executor=None, fail_fast=None, host_aliases=None, http=None, init_containers=None, inputs=Inputs(artifacts=None, parameters=[Parameter(default=None, description=None, enum=None, global_name=None, name='tile', value=None, value_from=None), Parameter(default='/eodc/private/openeo_platform/zarr_nacho/s1sig0.zarr', description=None, enum=None, global_name=None, name='store_path', value=None, value_from=None)]), memoize=None, metadata=Metadata(annotations=None, labels=None), metrics=None, name='write-data', node_selector=None, outputs=Outputs(artifacts=None, exit_code=None, parameters=None, result=None), parallelism=None, plugin=None, pod_spec_patch=None, priority=None, priority_class_name=None, resource=None, retry_strategy=None, scheduler_name=None, script=ScriptTemplate(args=None, command=['python'], env=None, env_from=None, image='ghcr.io/oscipal/image_zarr:latest', image_pull_policy=None, lifecycle=None, liveness_probe=None, name='', ports=None, readiness_probe=None, resources=ResourceRequirements(limits=None, requests=None), security_context=None, source=\"import os\\nimport sys\\nsys.path.append(os.getcwd())\\nimport json\\ntry: store_path = json.loads(r'''{{inputs.parameters.store_path}}''')\\nexcept: store_path = r'''{{inputs.parameters.store_path}}'''\\ntry: tile = json.loads(r'''{{inputs.parameters.tile}}''')\\nexcept: tile = r'''{{inputs.parameters.tile}}'''\\n\\nimport pystac_client as pc\\nimport xarray as xr\\nimport zarr\\nimport numpy as np\\nimport rioxarray\\nimport pandas as pd\\n\\ndef get_idx(array1, array2):\\n    min = np.where(array1 == array2[0])[0][0]\\n    max = np.where(array1 == array2[-1])[0][0] + 1\\n    return (min, max)\\n\\ndef load_data(item, pols):\\n    if type(pols) == str:\\n        data = rioxarray.open_rasterio(item.assets[pols].href).load().expand_dims(time=pd.to_datetime([item.properties['datetime']]).tz_convert(None)).rename(pols)\\n    else:\\n        data = []\\n        for pol in pols:\\n            data.append(rioxarray.open_rasterio(item.assets[pol].href).load().expand_dims(time=pd.to_datetime([item.properties['datetime']]).tz_convert(None)).rename(pol))\\n        data = xr.merge(data)\\n    return data.squeeze()\\n\\ndef clip_data(dataset, fillvalue=-9999, multiple_vars=False):\\n    if len(list(dataset.data_vars)) > 1 and (not multiple_vars):\\n        raise Warning('All variables are clipped to the extent of first variable! Set multiple_vars to TRUE if you want to proceed.')\\n    mask = dataset[list(dataset.data_vars)[0]] != fillvalue\\n    ymin, ymax = [np.where(mask)[0].min(), np.where(mask)[0].max() + 1]\\n    xmin, xmax = [np.where(mask)[1].min(), np.where(mask)[1].max() + 1]\\n    data = dataset.isel(x=slice(xmin, xmax), y=slice(ymin, ymax))\\n    return data\\npc_client = pc.Client.open('https://stac.eodc.eu/api/v1')\\ntime_range = '2022-01-01/2022-01-30'\\nprint(tile)\\nsearch = pc_client.search(collections=['SENTINEL1_SIG0_20M'], datetime=time_range, query={'Equi7_TileID': {'eq': f'EU020M_{tile}T3'}})\\nitems_eodc = search.item_collection()\\nitem_list = list(items_eodc)[::-1]\\nstore = zarr.storage.LocalStore(store_path)\\ngroup = zarr.group(store=store)\\nx_extent = group['x'][:]\\ny_extent = group['y'][:]\\nprint(len(items_eodc))\\nfor item in item_list:\\n    print('alala')\\n    dataset = load_data(item, ['VH', 'VV'])\\n    dataset['x'] = dataset.x - 10\\n    dataset['y'] = dataset.y + 10\\n    dataset_clipped = clip_data(dataset, multiple_vars=True)\\n    aon = dataset_clipped.attrs['abs_orbit_number']\\n    ron = dataset_clipped.attrs['rel_orbit_number']\\n    dataset = None\\n    time_origin = np.datetime64('2014-10-01')\\n    times = dataset_clipped.time.values.astype('datetime64[D]')\\n    time_delta = (times - time_origin).astype('int64')\\n    sensing_origin = np.datetime64('2014-10-01T00:00:00')\\n    sensing = dataset_clipped.time.values.astype('datetime64[s]')\\n    sensing_delta = (sensing - sensing_origin).astype('int64')\\n    x_min, x_max = get_idx(x_extent, dataset_clipped['x'].values)\\n    y_min, y_max = get_idx(y_extent, dataset_clipped['y'].values)\\n    data_vh = dataset_clipped['VH'].values\\n    existing_data_vh = group['VH'][time_delta, y_min:y_max, x_min:x_max]\\n    np.copyto(existing_data_vh, data_vh, where=existing_data_vh == -9999)\\n    group['VH'][time_delta, y_min:y_max, x_min:x_max] = existing_data_vh\\n    data_vh = None\\n    data_vv = dataset_clipped['VV'].values\\n    existing_data_vv = group['VV'][time_delta, y_min:y_max, x_min:x_max]\\n    np.copyto(existing_data_vv, data_vv, where=existing_data_vv == -9999)\\n    group['VV'][time_delta, y_min:y_max, x_min:x_max] = existing_data_vv\\n    data_vv = None\\n    existing_data_vv = None\\n    new_aon = existing_data_vh.astype(np.int32)\\n    new_aon[new_aon != -9999] = aon\\n    group['absolute_orbit_number'][time_delta, y_min:y_max, x_min:x_max] = new_aon\\n    new_aon = None\\n    new_ron = existing_data_vh\\n    new_ron[new_ron != -9999] = ron\\n    group['relative_orbit_number'][time_delta, y_min:y_max, x_min:x_max] = new_ron\\n    new_ron = None\\n    new_sensing = existing_data_vh.astype(np.int64)\\n    existing_data_vh = None\\n    new_sensing[new_sensing != -9999] = int(sensing_delta)\\n    group['sensing_date'][time_delta, y_min:y_max, x_min:x_max] = new_sensing\\n    new_sensing = None\", startup_probe=None, stdin=None, stdin_once=None, termination_message_path=None, termination_message_policy=None, tty=None, volume_devices=None, volume_mounts=[VolumeMount(mount_path='/eodc', mount_propagation=None, name='eodc-mount', read_only=None, sub_path=None, sub_path_expr=None)], working_dir=None), security_context=None, service_account_name=None, sidecars=None, steps=None, suspend=None, synchronization=None, timeout=None, tolerations=None, volumes=None)], tolerations=None, ttl_strategy=None, volume_claim_gc=None, volume_claim_templates=None, volumes=[Volume(aws_elastic_block_store=None, azure_disk=None, azure_file=None, cephfs=None, cinder=None, config_map=None, csi=None, downward_api=None, empty_dir=None, ephemeral=None, fc=None, flex_volume=None, flocker=None, gce_persistent_disk=None, git_repo=None, glusterfs=None, host_path=None, iscsi=None, name='eodc-mount', nfs=None, persistent_volume_claim=PersistentVolumeClaimVolumeSource(claim_name='eodc-nfs-claim', read_only=None), photon_persistent_disk=None, portworx_volume=None, projected=None, quobyte=None, rbd=None, scale_io=None, secret=None, storageos=None, vsphere_volume=None)], workflow_metadata=None, workflow_template_ref=None), status=WorkflowStatus(artifact_gc_status=None, artifact_repository_ref=None, compressed_nodes=None, conditions=None, estimated_duration=None, finished_at=None, message=None, nodes=None, offload_node_status_version=None, outputs=None, persistent_volume_claims=None, phase=None, progress=None, resources_duration=None, started_at=None, stored_templates=None, stored_workflow_template_spec=None, synchronization=None, task_results_completion_status=None))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff6a6db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zarr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
